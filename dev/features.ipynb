{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data directory\n",
    "DATA_PATH = \"/home/mathuis/Development/cyber_wolf/data\"\n",
    "\n",
    "# Set feature definition\n",
    "FEATUE_DEF = [\"path\", \"header\", \"body\", \"length\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\",\n",
    "              \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\",\n",
    "              \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\",\n",
    "              \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\",\n",
    "              \"8\", \"9\", \"[\", \"\\\\\", \"]\", \"^\", \"_\", \"`\", \"{\", \"|\", \"}\", \"~\", \"!\", \"\\\"\", \"#\", \"$\", \"%\",\n",
    "              \"&\", \"'\", \"(\", \")\", \"*\", \"+\", \",\", \"-\", \".\", \"/\", \":\", \";\", \"<\", \">\", \"=\", \"?\", \"@\"]\n",
    "\n",
    "NORM_COLS = [\"length\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\",\n",
    "             \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\",\n",
    "             \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\",\n",
    "             \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\",\n",
    "             \"8\", \"9\", \"[\", \"\\\\\", \"]\", \"^\", \"_\", \"`\", \"{\", \"|\", \"}\", \"~\", \"!\", \"\\\"\", \"#\", \"$\", \"%\",\n",
    "             \"&\", \"'\", \"(\", \")\", \"*\", \"+\", \",\", \"-\", \".\", \"/\", \":\", \";\", \"<\", \">\", \"=\", \"?\", \"@\"]\n",
    "\n",
    "TEST_RATIO = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads a file and returns the lines as an array\n",
    "def read_file_content(data_path):\n",
    "    with open(data_path, \"r\") as f:\n",
    "        return f.readlines()\n",
    "\n",
    "\n",
    "# Loops through lines in request\n",
    "# Appends results tot base dataframe\n",
    "def extract_features(request):\n",
    "    df = pd.DataFrame(columns=FEATUE_DEF)\n",
    "\n",
    "    for i in range(len(request)):\n",
    "        frames = get_values(request, i)\n",
    "        df = df.append(frames, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Gets the features from the line\n",
    "# Returns features, appended to the base dataframe\n",
    "def get_values(request, i):\n",
    "    df = pd.DataFrame(columns=FEATUE_DEF)\n",
    "    line = request[i].strip()\n",
    "\n",
    "    # In query\n",
    "    if i == 0:\n",
    "        print(line)\n",
    "        values = split_query(line)\n",
    "        df = df.append(histogram(values, \"path\"), ignore_index=True)\n",
    "\n",
    "    # In header\n",
    "    if \": \" in line:\n",
    "        values = split_header(line)\n",
    "        df = df.append(histogram(values, \"header\"), ignore_index=True)\n",
    "        # return df\n",
    "\n",
    "    # In body\n",
    "    if line != \"\\n\" and \"\\n\" in request[0:i]:\n",
    "        print(line)\n",
    "        values = split_body(line)\n",
    "        df = df.append(histogram(values, \"body\"), ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Parses query values\n",
    "def split_query(line):\n",
    "    line = line.split(\" \")[1]\n",
    "\n",
    "    if \"?\" not in line:\n",
    "        return []\n",
    "\n",
    "    querystring = line.split(\"?\")[1]\n",
    "\n",
    "    if len(querystring) == 0:\n",
    "        return []\n",
    "\n",
    "    if \"&\" not in querystring:\n",
    "        return [querystring.split(\"=\")[1]]\n",
    "\n",
    "    values = []\n",
    "    sections = querystring.split(\"&\")\n",
    "    for section in sections:\n",
    "        if len(section.split(\"=\")) > 1:\n",
    "            values.append(section.split(\"=\")[1])\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "# Parses header values\n",
    "def split_header(line):\n",
    "    return [line.split(\": \")[1]]\n",
    "\n",
    "\n",
    "# Parses body values\n",
    "def split_body(line):\n",
    "    if \"&\" not in line:\n",
    "        if len(line.split(\"=\")) > 1:\n",
    "            return [line.split(\"=\")[1]]\n",
    "        else:\n",
    "            return [\"\"]\n",
    "\n",
    "    values = []\n",
    "    parameters = line.split(\"&\")\n",
    "    for param in parameters:\n",
    "        if len(param.split(\"=\")) > 1:\n",
    "            values.append(param.split(\"=\")[1])\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "# Generates the row in the dataframe\n",
    "# Builds histogram of the data\n",
    "def histogram(values, location):\n",
    "    req_df = pd.DataFrame(columns=FEATUE_DEF)\n",
    "\n",
    "    for value in values:\n",
    "        df = pd.DataFrame(columns=FEATUE_DEF)\n",
    "        # Set default values\n",
    "        df.loc[0] = 0\n",
    "        row = df.loc[0]\n",
    "        row[\"length\"] = len(value)\n",
    "        row[location] = 1\n",
    "\n",
    "        for char in value:\n",
    "            if char == \" \":\n",
    "                continue\n",
    "\n",
    "            row[char] += 1\n",
    "\n",
    "        req_df = req_df.append(df, ignore_index=True)\n",
    "\n",
    "    return req_df\n",
    "\n",
    "\n",
    "# Normalizes the correct values\n",
    "def normalize(df):\n",
    "    # Normalize histogram\n",
    "    # The normalized count is the count in a class divided by the total number of observations.\n",
    "    # In this case the relative counts are normalized to sum to one (or 100 if a percentage scale is used).\n",
    "    # This is the intuitive case where the height of the histogram bar represents the proportion of the data in each class.\n",
    "\n",
    "    # Calculate the sum for each column\n",
    "    # Calculate normalized ratio based on sum for each row and col in base dataframe\n",
    "    for col in NORM_COLS:\n",
    "        print(f\"Normalizing: {col}\")\n",
    "        if df[col].sum() != 0:\n",
    "            df[col] = df.apply(lambda x: x[col] / df[col].sum(), axis=1)\n",
    "\n",
    "        print(f\"Total: {df[col].sum()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(request):\n",
    "    print(\"Preprocessing request\")\n",
    "    x = extract_features(request)\n",
    "    x = np.asarray(x).astype(\"float32\")\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base data frame\n",
    "df = pd.DataFrame(columns=FEATUE_DEF)\n",
    "\n",
    "files = os.listdir(f\"{DATA_PATH}/requests\")\n",
    "\n",
    "print(f\"Preprocessing {len(files)} requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    # Read request contents\n",
    "    file_contents = read_file_content(f\"{DATA_PATH}/requests/{file}\")\n",
    "\n",
    "    # Extract features from contents\n",
    "    features = extract_features(file_contents)\n",
    "\n",
    "    # Add data to the base dataframe\n",
    "    df = df.append(features, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle random\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize dataset\n",
    "# df = normalize(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the training set size\n",
    "train_count = int(len(df) - len(df) * TEST_RATIO)\n",
    "\n",
    "x_train = df[0:train_count].to_numpy()\n",
    "x_test = df[train_count:len(df) + 1].to_numpy()\n",
    "\n",
    "x_train = np.asarray(x_train).astype(\"float32\")\n",
    "x_test = np.asarray(x_test).astype(\"float32\")\n",
    "\n",
    "# Save complete dataset to csv\n",
    "df.to_csv(f\"{DATA_PATH}/datasets/notnorm_dataset.csv\")\n",
    "np.save(f\"{DATA_PATH}/datasets/notnorm_x_train\", x_train)\n",
    "np.save(f\"{DATA_PATH}/datasets/notnorm_x_test\", x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}